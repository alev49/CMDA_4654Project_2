---
title: "CMDA-4654  \n Homework Template"
subtitle: "Group Exercise 2"
author: "Alex Vidal and Seth Eshraghi"
date: "March 16, 2024"
output:
  pdf_document:
    highlight: haddock
keep_tex: no
number_sections: no
html_document:
  df_print: paged
geometry: margin = 0.5in
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
documentclass: article
urlcolor: blue
---

<!-- The above is set to automatically compile to a .pdf file.   -->

<!-- It will only succeed if LaTeX is installed. -->

<!-- If you absolutely can't get LaTeX installed and/or working, then you can compile to a .html first,  -->

<!-- by clicking on the arrow button next to knit and selecting Knit to HTML. -->

<!-- You must then print you .html file to a .pdf by using first opening it in a web browser and then printing to a .pdf -->

```{r setup, include=FALSE}
# This is the setup chunk
#  Here you can set global options for the entire document

library(knitr) # I recommend doing this here

# Although you can call functions from a library using the following notation
#  without loading the entire library.
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, # Required
                      fig.path = "./figures/",  # Store all figures here in relative path (make the folder first)
                      fig.align = "center",
                      fig.width = 7,
                      fig.height = 7,
                      message = FALSE, # Turn off load messages
                      warning = FALSE # Turn off warnings
                      )

```

\clearpage

```{r include=FALSE}
# You should not echo this chunk.
# include=FALSE does more than echo=FALSE, it actually does: echo=FALSE, results='hide', message=FALSE, warning=FALSE, fig.show='hide'

# You should set your working directory at the very beginning of your R Markdown file
setwd("/Users/alexvidal/Desktop/CMDA_4654/")

```


# Part 1

Testing loess
```{r}
#data from https://www.itl.nist.gov/div898/handbook/pmd/section1/dep/dep144.htm 
testData <- read.csv("exData.csv", header = FALSE,col.names = c("x", "y")) 
model <- loess(y~x,data=testData, span = 1/3,degree = 2,family = "symmetric")
model$fitted
```


## Function
```{r}
library(ggplot2)
# Gets a single x point and finds n closest points to xPt in points along with their corresponding weights
# Returns a data frame of those n closest to xPt points with columns x, y and wieght 
# points is a data frame with columns x and y and N rows so n<N
minPoint <- function(xPt, points, n){
  closestX <- c()
  closestY <- c()
  weight <- c()
  minDists <- sort((abs(xPt-points$x)))[1:n] 
  maxDist <- max(minDists)
  minDists <- minDists/maxDist
  for(index in 1:nrow(points)){
    distBetween <- abs(xPt-points$x[index])/maxDist
    if(distBetween  %in% minDists){
      closestX <- c(closestX, points$x[index])
      closestY <- c(closestY, points$y[index])
      minDists <- minDists[-match(distBetween, minDists)]
      if(distBetween>=1){
        weight <- c(weight, 0)
      }
      else{
        weight <- c(weight, (1-distBetween^3)^3)
      }
    }
  }
  closest <- data.frame(closestX, closestY, weight)
  return(closest)
}


# Your function will have the following inputs.
# 
# * x - a numeric input vector
# * y - a numeric response
#
# Note span and degree are shown with their default values. (Read about this in the description)
# * degree should be 1 or 2 only
# * span can be any value in interval (0, 1) non-inclusive.
#
# If show.plot = TRUE then you must show a plot of either the final fit

myloess <- function(x, y, span = 0.5, degree = 1, show.plot = TRUE){
  N <- length(x)
  points <- data.frame(x,y) #Creating a matrix for x and y points
  regValues <- c()
  for(index in 1:N){
    # The subset of points that also include weights for each point
    pointData <- minPoint(points$x[index], points, round(span*N))
    if(degree==1){
      pointModel <- lm(closestY~closestX, data = pointData, weights = pointData$weight)
      # The regression values or the fitted values at the points according to the weighted regression
      regValues <- c(regValues, pointModel$coefficients[1]+pointModel$coefficients[2]*points$x[index])
    }
    else if(degree==2){
      #Creating the 2nd parameter for our 2 degree polynomial
      pointData$closestXSquared <- pointData$closestX^2
      pointModel <- lm(closestY~closestX+closestXSquared, data = pointData, weights = pointData$weight)
      # Storing the fitted value in regValues
      regValues <- c(regValues, pointModel$coefficients[1]+pointModel$coefficients[2]*points$x[index]+pointModel$coefficients[3]*(points$x[index])^2)
    }
    else{
      print("Error: Degree too large")
    }
  }
  SSE <- sum((points$y-regValues)^2)
  fittedData <- data.frame(x=points$x, y=regValues)
  thePlot <- ggplot()+
    geom_point(data = points,aes(x=x, y=y))+
    geom_line(data = fittedData, aes(x=x, y=y))+
    labs(title=paste(" LOESS Plot with", degree, "Degree Polynomial", "\n", "with Span:", span, sep = " "),
        x ="x variable", y = "y variable")
  result <- list(Span=span, degree=degree, N_total=N, SSE=SSE, loessplot=thePlot)
  if(show.plot){
    plot(thePlot)
  }
  
  return(result) 
}

# Your function should return a named list containing the following:
# span: proportion of data used in each window (controls the bandwidth)
# degree: degree of polynomial
# N_total: total number of points in the data set
# SSE: Error Sum of Squares (Tells us how good of a fit we had).
# loessplot: An object containing the ggplot so that we can see the plot later. 
#  We want this even if show.plot = FALSE
#  Note: you are NOT allowed to simply use stat_smooth() or geom_smooth() to have it automatically do LOESS.
#  You should use geom_line() or similar to plot your final the LOESS curve.

# Make sure you can access the objects properly using the $ notation.
```


## Problem 1
```{r}
bruh <- myloess(testData$x, testData$y, span = .333, degree = 2, show.plot = FALSE)
bruh$SSE
fitty <- loess(testData$y~testData$x, span = .333, degree = 2)

load("ozone.RData")
head(ozone)

wotty <- ggplot(data = ozone, aes(x=radiation, y=temperature))+
  geom_line()+
  geom_point(aes(x=radiation, y=temperature))
data.frame(bruh = 1,theplot=test, dawg=wotty)
test <- list(a=1,b="a",c=2.3,d=5)
wotty
```

### 1.
```{r}
for(i in 1:6){
  fit <- lm(ozone~poly(temperature, i), data = ozone)
  print(paste("Sum of Squares Residual for",i ,"degree polynomial is:",sum(fit$residuals^2), sep = " "))
  print(summary(fit))
}
```

I would say that based on the adjusted R squared the sweet spot for the model to have the least amount of parameters with the best fit would be 4 degree polynomial. Since the adjusted R-squared for degree 4 is the highest as even though the regular R-squared keeps going up for the 5 adn 6 degree polynomials, it is only barely and we are adding more unnecessary parameters. 

### 2. 
```{r}
SSETable <- matrix(1, ncol=11, nrow = 2,byrow=TRUE)
plotTable <- matrix(1, ncol=11, nrow = 2,byrow=TRUE)
for(j in 1:2){
  index <- 1
  for(i in seq(.25,.75, by=.05)){
    fit <- myloess(ozone$ozone, ozone$temperature, span=i, degree = j, show.plot = FALSE)
    SSETable[j, index] <- fit$SSE
    index <- index+1
  }
}
colnames(SSETable) <- c(seq(.25,.75, by=.05))
rownames(SSETable) <- c(1,2)

print("Sum of Squares Error Table")
print(SSETable)

print("Best Fitted Plots by Polynomial Degree")
spans <- seq(.25,.75, by=.05)
for(i in 1:2){
  for (j in 1:3){
    fit <- myloess(ozone$ozone, ozone$temperature, span=spans[j], degree = i)
  }
}
```

All the best plots for both degree 1 and degree 2 had the lowest spans since they were probably over fitting in some areas especially as seen in the degree 2 span .25 plot. In the beginning the line varies greatly and is not as smooth as I would like to be used in modeling. Degree 2 span of .35 actually looks much smoother and if you look at the SSE Table it is not that much difference in SSE compared to .3. For degree 1 even with span of .25 it's SSE is still not lower than degree 2 span of .35 but looks smoother than it. Overall degree 2 span of .25 and .3 look very over fitting and even span of .35 does a bit while degree 1 span of .25 is slight over fitting with the other spans looking pretty smooth. 

## Problem 2
```{r}
library(MASS)
data("mcycle")
```

### 1.
```{r}
SSETable <- matrix(1, ncol=11, nrow = 2,byrow=TRUE)
plotTable <- matrix(1, ncol=11, nrow = 2,byrow=TRUE)
for(j in 1:2){
  index <- 1
  for(i in seq(.25,.75, by=.05)){
    fit <- myloess(mcycle$times, mcycle$accel, span=i, degree = j, show.plot = FALSE)
    SSETable[j, index] <- fit$SSE
    index <- index+1
  }
}

colnames(SSETable) <- c(seq(.25,.75, by=.05))
rownames(SSETable) <- c(1,2)

print("Sum of Squares Error Table")
print(SSETable)

bestSpans <- c(.25,.3,.35)
for(i in 1:2){
  for (j in 1:3){
    fit <- myloess(mcycle$times, mcycle$accel, span=bestSpans[j], degree = i)
  }
}
```

Based on visuals the best looking fit for the data looks to be in the degree 2 polynomial fit as degree 1 fit are just too smooth and dampened so they don't look that well fit. For teh degree 2 span the SSE for .25 says it is the best but .3 and .35 look the smoothest with some decrease in SSE. 

# Part 2

## Function
```{r}
# Your function will have the following inputs similar to what you would find with the
#  knn() function
#
# * train - matrix or data frame of training set cases
# * test - matrix or data frame of test set cases.  
#     (A vector will be interpreted as a row vector for a single case.)
# * y_train - Either a numeric vector, or factor vector for the responses in the training set
# * y_test - Either a numeric vector, or factor vector for the responses in the testing set
# * k - number of neighbors considered, the default value is 3
#
# If weighted = TRUE, then your function must used the distance weighted kNN as described above,
#  otherwise it should do the default knn method.


mykNN <- function(train, test, y_train, y_test, k = 3, weighted = TRUE){

  # Your code goes here

  return(list of objects seen below)

}

# If you are doing classification, then your function must return:
#  * A factor vector (yhat) for the predicted categories for the testing data
#  * The accuracy of the classification
#  * The error rate = 1 - accuracy
#  * A confusion matrix
#  * The value of k used

# If you are doing regression, then your function must return:
#  * A numeric vector (yhat) for the predicted responses for the testing data
#  * The residual vector
#  * The SSE
#  * The value of k used
```

## Problem 3


## Problem 4
